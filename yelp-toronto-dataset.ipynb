{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Health Inspection Violaitons from Yelp Reviews and Business Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2 as psy\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import scipy.sparse\n",
    "import sklearn.pipeline as pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to database and download initial datasets. These datasets are materialized views of the Yelp business data converted from JSON format, and the Toronto Inspection dataset imported from CSV. All attributes have been normalized to remove leading spaces, JSON tags, and unreadable characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#set up connection to our DB\n",
    "conn = psy.connect(database=\"sterndsyelp\", \n",
    "                        user=\"mvsternds\", \n",
    "                        password=\"nyustern123!\", \n",
    "                        host=\"sterndsyelp.cawzspvmqd5q.us-east-1.rds.amazonaws.com\", \n",
    "                        port=\"5432\"\n",
    "                       )\n",
    "#open cursor and check our tables in the DB\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get Yelp review text\n",
    "cur.execute(\"SELECT * FROM public.toronto_reviews\")\n",
    "reviews = pd.DataFrame(cur.fetchall())\n",
    "reviews.columns = ['bizID','reviewID','userID','type','stars','text','useful','funny','cool','date']\n",
    "\n",
    "#get total reviews per biz\n",
    "rev = reviews['bizID'].value_counts()\n",
    "rev_counts = pd.DataFrame(rev).reset_index()\n",
    "rev_counts.columns = ['bizID','all_review_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Yelp Review Data with Inspection Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Levenshtein Distance (in-database) \n",
    "This option joins the yelp restaurant informaiton to each inspection record where:\n",
    " * The [Levenshtein distance](https://xlinux.nist.gov/dads/HTML/Levenshtein.html) of the restaurant name from the two datasets is <3\n",
    " * The distance of the address from each dataset is <4\n",
    " * The date of the review is greater than the prior inspection date\n",
    " * The date of the review is less than or equal to inspeciton date on the record\n",
    " * The absolute value difference of the \"star\" rating in the review is less than or equal to 2 (this may reduce biased reviews that are too far from the mean)\n",
    " \n",
    "Whitespace at the beginning and end of the name and address in each dataset is trimmed, and the strings are converted to uppercase before matching. The mathcing thresholds can be adjusted to increase potential for matching, or decrease false matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The materialized view of the restaurant, inspection, and review data is \"toronto_all\"\n",
    "cur.execute(\"SELECT * FROM public.toronto_all_3 where review_date is not null and attributes is not null order by  establishment_id, inspection_date\" )\n",
    "obs = pd.DataFrame(cur.fetchall())\n",
    "obs.head()\n",
    "obs.columns=['bizID','name','address','postal_code','neighborhood','lat','long','categories','attributes','is_open','review_cnt','hours','stars','setablishment_id','establishment_name','establishment_address','inspection_date','last_inspection','count_minor','count_sig','count_crucial','count_na','count_crucial_signficant','review_id','user_id','review_stars','review_text','useful','funny','cool','review_dt','last_insp_cs']\n",
    "obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a primary key of restaurant ID and each unique inspection date for that restaurant\n",
    "obs['bizID-dt'] = obs['bizID'] + \"-\" + obs['inspection_date'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get counts of in scope reviews for each inspeciton date of a given restaurant\n",
    "in_scope_rev = obs['bizID-dt'].value_counts()\n",
    "in_scope_reviews = pd.DataFrame(in_scope_rev).reset_index()\n",
    "in_scope_reviews.columns = ['bizID-dt','count_reviews_in_scope']\n",
    "in_scope_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get dummies for star rating column\n",
    "obs = pd.concat([obs, pd.get_dummies(obs['review_stars'], prefix='stars')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get counts of each star rating for a given restaurant\n",
    "stars = obs.groupby('bizID-dt')[['stars_1', 'stars_2','stars_3','stars_4','stars_5']].sum().reset_index()\n",
    "stars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge review text based on the business-inspection date primary key\n",
    "combined_revs = obs.groupby('bizID-dt')['review_text'].apply(' '.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a unique count of the users that reviewed the restaurant after the last inspection \n",
    "#and before the current inspection\n",
    "users = obs.groupby('bizID-dt')['user_id'].count().reset_index()\n",
    "users.columns = ['bizID-dt','count_unique_users']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = obs[['bizID-dt','bizID',\n",
    "           'name','postal_code',\n",
    "           'lat','long','categories',\n",
    "           'attributes','is_open',\n",
    "           'count_crucial_signficant','stars', 'last_insp_cs']]\n",
    "sub = sub.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#merge in all data into one df\n",
    "df1 = pd.merge(sub,stars,on='bizID-dt', how='left')\n",
    "df2 = pd.merge(df1,combined_revs,on='bizID-dt', how='left')\n",
    "df3 = pd.merge(df2,rev_counts,on='bizID', how='left')\n",
    "df4 = pd.merge(df3,in_scope_reviews,on='bizID-dt', how='left')\n",
    "df5 = pd.merge(df4,users,on='bizID-dt', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the \"Categories\" and \"Attributes\" columns into unique features\n",
    "The next cell parses the 'Categories' and 'Attributes' columns,which are nested dicitonaries of different attributesof each restaurant. The categroy column captures descriptive features such as the types of cuisine served, and wheter or not the restaurant is a bar. The atttributes column captures features such as the 'ambiance' of the restaurant, parking, noise level, and other unique features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = []\n",
    "for i in range(len(df5['categories'])):\n",
    "    x = ast.literal_eval(df5['categories'][i])\n",
    "    t.append(x)\n",
    "    \n",
    "cats = pd.DataFrame(t)\n",
    "cats_df = pd.get_dummies(cats, prefix='Category')\n",
    "cats_df = cats_df.groupby(cats_df.columns, axis=1).sum()\n",
    "\n",
    "\n",
    "atts_df = pd.DataFrame()\n",
    "for x in range(len(df5['attributes'])):\n",
    "    list_yelp = ast.literal_eval(df5['attributes'][x])\n",
    "\n",
    "    attribute_list = []\n",
    "    attribute_name = []\n",
    "\n",
    "    for i in list_yelp:\n",
    "\n",
    "        name = i.split(\":\")[0]\n",
    "        values = i.split( name+\": \" )[1].replace('{','').replace('}','')\n",
    "\n",
    "        if len(values.split(\":\")) > 1: \n",
    "        \n",
    "            for j in values.split(\",\"):\n",
    "                name_j = name + \"_\" + (j.split(\":\")[0].strip().replace(\"'\",''))\n",
    "                attribute_name.append( name_j )\n",
    "                attribute_list.append (j.split(\":\")[1])\n",
    "        else:\n",
    "            attribute_name.append( name )\n",
    "            attribute_list.append ( values )\n",
    "        \n",
    "    dataframe = pd.DataFrame(attribute_list).transpose()\n",
    "    dataframe.columns = attribute_name\n",
    "    atts_df = atts_df.append(dataframe)\n",
    "    \n",
    "atts_df = atts_df.reset_index().drop('index', 1)\n",
    "\n",
    "df = pd.concat([df5, cats_df, atts_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create dummy variables for all of the attribute and category features that were generated in the previous step. We want to capture if the attribute is true, false, or nor applicable for the restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dummy-ize all categorical and boolean variables\n",
    "df=pd.get_dummies(df, columns=[\n",
    " 'Alcohol',\n",
    " 'Ambience_casual',\n",
    " 'Ambience_classy',\n",
    " 'Ambience_hipster',\n",
    " 'Ambience_intimate',\n",
    " 'Ambience_romantic',\n",
    " 'Ambience_touristy',\n",
    " 'Ambience_trendy',\n",
    " 'Ambience_upscale',\n",
    " 'BikeParking',\n",
    " 'BusinessAcceptsCreditCards',\n",
    " 'BusinessParking_garage',\n",
    " 'BusinessParking_lot',\n",
    " 'BusinessParking_street',\n",
    " 'BusinessParking_valet',\n",
    " 'BusinessParking_validated',\n",
    " 'Caters',\n",
    " 'GoodForKids',\n",
    " 'GoodForMeal_breakfast',\n",
    " 'GoodForMeal_brunch',\n",
    " 'GoodForMeal_dessert',\n",
    " 'GoodForMeal_dinner',\n",
    " 'GoodForMeal_latenight',\n",
    " 'GoodForMeal_lunch',\n",
    " 'HasTV',\n",
    " 'NoiseLevel',\n",
    " 'OutdoorSeating',\n",
    " 'RestaurantsAttire',\n",
    " 'RestaurantsDelivery',\n",
    " 'RestaurantsGoodForGroups',\n",
    " 'RestaurantsPriceRange2',\n",
    " 'RestaurantsReservations',\n",
    " 'RestaurantsTableService',\n",
    " 'RestaurantsTakeOut',\n",
    " 'WiFi', \n",
    " 'is_open',\n",
    "'BestNights_friday',\n",
    " 'BestNights_monday',\n",
    " 'BestNights_saturday',\n",
    " 'BestNights_sunday',\n",
    " 'BestNights_thursday',\n",
    " 'BestNights_tuesday',\n",
    " 'BestNights_wednesday',\n",
    "     'ByAppointmentOnly',\n",
    " 'CoatCheck',\n",
    " 'DogsAllowed',\n",
    " 'DriveThru',\n",
    " 'GoodForDancing',\n",
    " 'HappyHour',\n",
    " 'Music_background_music',\n",
    " 'Music_dj',\n",
    " 'Music_jukebox',\n",
    " 'Music_karaoke',\n",
    " 'Music_live',\n",
    " 'Music_no_music',\n",
    " 'Music_video',\n",
    " 'Open24Hours',\n",
    " 'RestaurantsCounterService',\n",
    " 'Smoking',\n",
    " 'WheelchairAccessible'\n",
    "  ]\n",
    "  , dummy_na=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#useful code to view all columns of df\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove all of the extraneous features\n",
    "#backup=df\n",
    "del df['categories']\n",
    "del df['attributes']\n",
    "del df['name']\n",
    "del df['bizID']\n",
    "del df['bizID-dt']\n",
    "del df['lat']\n",
    "del df['long']\n",
    "del df['postal_code']\n",
    "#Make a True/False target variable to label each inspection event with wether or not a critical violaton was found\n",
    "df['count_crucial_signficant']= (df['count_crucial_signficant']>0)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text feature extraction, stop word removal, and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import string\n",
    "stemmer = PorterStemmer()\n",
    "stop = stopwords.words('english')\n",
    "df['review_text']=df['review_text'].str.lower()\n",
    "df['review_text'] = df['review_text'].apply(lambda x: '  '.join([word for word in x.split() if word not in (stop)]))\n",
    "# ps = nltk.stem.WordNetLemmatizer()\n",
    "# df['review_text']=df[\"review_text\"].apply(lambda x:[ps.lemmatize(y,pos='v') for y in x.split()])\n",
    "df['review_text']=df[\"review_text\"].apply(lambda x:[stemmer.stem(y) for y in x.split()])\n",
    "df['review_text']=df['review_text'].apply(lambda x: ',  '.join(x))\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "df['review_text'] = df['review_text'].str.translate(translator)\n",
    "df['stars'] = df.stars.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling and Text Vectorization\n",
    "First, we import all necessary packages. By comparing the results of several vectorizing methods as well as several moeling methods, we can determine which combination yield best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = df[df['count_reviews_in_scope'] >0]\n",
    "X_ntext = df_test.drop(['review_text','count_crucial_signficant'], axis=1)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#separate the non text features so that we only transform the text\n",
    "X_text = df_test['review_text']\n",
    "X_ntext = df_test.drop(['review_text','count_crucial_signficant'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up a few different vectorizers to test\n",
    "count_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "bigram_vectorizer = TfidfVectorizer(ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "##### Basic Linear Regression 3-fold CV , TfidfVectorizer(ngram_range = (1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize using count vectorizer and 3-gram features and create train/test split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X1 = scipy.sparse.hstack((bigram_vectorizer.fit_transform(df_test.review_text), X_ntext.values),format='csr')\n",
    "Y1 = df_test['count_crucial_signficant']\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X1, Y1, train_size=.75)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr_parameters = {'C':[0.001,0.1,1,10],\n",
    "                'penalty':['l1','l2']}\n",
    "\n",
    "lr_cv = GridSearchCV(lr,lr_parameters)\n",
    "lr_cv.fit(X_train1,Y_train1)\n",
    "\n",
    "print(\"Best parameters set found on development set:\"+str(lr_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print (\"Average AUC using 3-fold CV and optimized parameters on test data = %.3f\" % \n",
    "        np.mean(cross_val_score(lr_cv, X_test1, Y_test1, scoring=\"roc_auc\", cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Linear Regression 3-fold CV , CountVectorizer(binary=True, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize using hash vectorixer and tfidf and create train/test split\n",
    "X2 = scipy.sparse.hstack((count_vectorizer.fit_transform(df_test.review_text), X_ntext.values),format='csr')\n",
    "Y2 = df['count_crucial_signficant']\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X2, Y2, train_size=.75)\n",
    "\n",
    "lr2 = LogisticRegression()\n",
    "lr_parameters = {'C':[0.0001,0.001,0.01,0.1,1,10],\n",
    "                'penalty':['l1','l2']}\n",
    "lr_cv2 = GridSearchCV(lr,lr_parameters)\n",
    "lr_cv2.fit(X_train2, Y_train2)\n",
    "\n",
    "print(\"Best parameters set found on development set:\"+str(lr_cv2.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = np.mean(cross_val_score(lr_cv2, X_test2, Y_test2, scoring=\"roc_auc\", cv=5))\n",
    "print (\"Average AUC using 3-fold CV and optimized parameters on test data = %.3f\" % \n",
    "     auc  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparison of CountVectorizer optimized Linear Regression to TFIDFVectorizer Optimized Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 8\n",
    "\n",
    "# Get the probability of Y_test records being = 1\n",
    "Y_test_probability_1 = lr_cv2.predict_proba(X_test2)[:, 1]\n",
    "\n",
    "#Use the metrics.roc_curve function to get the true positive rate (tpr) and false positive rate (fpr)\n",
    "tpr, fpr, thresholds = metrics.roc_curve(Y_test2, Y_test_probability_1)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(tpr, fpr, label=\"AUC - LR with optimized parameters and count vectorizer: \" + str(round(auc, 2)))\n",
    "    \n",
    "plt.xlabel(\"False positive rate (fpr)\")\n",
    "plt.ylabel(\"True positive rate (tpr)\")\n",
    "plt.plot([0,1], [0,1], 'k--', label=\"Random\")\n",
    "plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train2, Y_train2)\n",
    "\n",
    "print (\"Area under the ROC curve on test data = %.3f\" % metrics.roc_auc_score(rf.predict(X_test2), Y_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the grid search tests above, we see that neither Linear Regression not Random Forests seem to yield results that are siginificantly better than random.\n",
    "\n",
    "Other methods including Gradient Descent and a Restricted Boltazman Machine Neural Net are implemented below. Because the count vectorizer performed better than the TFIDF vectorizer, we use this vectorization in these methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', penalty='L2')\n",
    "clf.fit(X_train2,Y_train2)\n",
    "\n",
    "auc = np.mean(cross_val_score(clf, X_test2, Y_test2, scoring=\"roc_auc\", cv=3))\n",
    "\n",
    "# Get the probability of Y_test records being = 1\n",
    "Y_test_probability_1 =clf.predict_proba(X_test2)[:, 1]\n",
    "\n",
    "#Use the metrics.roc_curve function to get the true positive rate (tpr) and false positive rate (fpr)\n",
    "tpr, fpr, thresholds = metrics.roc_curve(Y_test2, Y_test_probability_1)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(tpr, fpr, label=\"AUC - LR with optimized parameters and count vectorizer: \" + str(round(auc, 2)))\n",
    "    \n",
    "plt.xlabel(\"False positive rate (fpr)\")\n",
    "plt.ylabel(\"True positive rate (tpr)\")\n",
    "plt.plot([0,1], [0,1], 'k--', label=\"Random\")\n",
    "plt.legend(loc=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restricted Boltzmann Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import BernoulliRBM\n",
    "\n",
    "# X1 = scipy.sparse.hstack((bigram_vectorizer.fit_transform(df_test.review_text), X_ntext))\n",
    "# Y1 = df_test['count_crucial_signficant']\n",
    "# X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X1, Y1, train_size=.75)\n",
    "\n",
    "# model = BernoulliRBM()\n",
    "# model.learning_rate = 0.06\n",
    "# model.n_iter = 20\n",
    "# # More components tend to give better prediction performance, but larger\n",
    "# # fitting time\n",
    "# model.n_components = 100\n",
    "\n",
    "# model.fit(X_train1, Y_train1)\n",
    "# auc_nn = metrics.roc_auc_score(model.predict(X_test1), Y_test1)\n",
    "# print (\"Area under the ROC curve on test data = %.3f\" % aud_nn )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
